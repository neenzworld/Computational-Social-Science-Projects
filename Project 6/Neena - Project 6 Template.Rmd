---
title: 'Project 6: Randomization and Matching'
output:
html_document:
df_print: paged
name: Neena
---

# Introduction

```{r}
# Load tidyverse and MatchIt
# Feel free to load other libraries as you wish
library(tidyverse)
library(MatchIt)

# Load ypsps data
ypsps <- read_csv('data/ypsps.csv')
head(ypsps)
```

# Randomization

Matching is usually used in observational studies to to approximate random assignment to treatment. But could it be useful even in randomized studies? To explore the question do the following:

# Generate a vector that randomly assigns each unit to either treatment or control
    # Choose a baseline covariate (for either the student or parent). A binary covariate is probably best for this exercise.
   # Visualize the distribution of the covariate by treatment/control condition. Are treatment and control balanced on this covariate?
    # Simulate the first 3 steps 10,000 times and visualize the distribution of treatment/control balance across the simulations.
# end{enumerate}

```{r}
# Generate a vector that randomly assigns each unit to treatment/control
set.seed(31)    # Set random seed for reproducibility

n_units <- 1000  # Number of units
treatment_vector <- sample(c(0, 1), size = n_units, replace = TRUE)  # 0 for control, 1 for treatment

# Choose a baseline covariate (use dplyr for this)
baseline_covariate <- sample(c(0, 1), size = n_units, replace = TRUE)  # Binary baseline covariate

# Visualize the distribution by treatment/control (ggplot)
# Create a data frame
data <- tibble(
  treatment = factor(treatment_vector, labels = c("Control", "Treatment")),
  baseline_covariate = factor(baseline_covariate, labels = c("No", "Yes"))
)

# Plot
ggplot(data, aes(x = baseline_covariate, fill = treatment)) +
  geom_bar(position = "fill") +
  labs(
    title = "Distribution of Baseline Covariate by Treatment/Control",
    x = "Baseline Covariate",
    y = "Proportion",
    fill = "Treatment"
  ) +
  scale_fill_manual(values = c("skyblue", "red")) +
  theme_minimal()


# Simulate this 10,000 times (monte carlo simulation - see R Refresher for a hint)
simulate_balance <- function(n_simulations, n_units) {  # Create a function to simulate the process and calculate balance
  balance <- numeric(n_simulations)
  for (i in 1:n_simulations) {
    treatment_vector <- sample(c(0, 1), size = n_units, replace = TRUE)
    baseline_covariate <- sample(c(0, 1), size = n_units, replace = TRUE)
    control_prop <- mean(baseline_covariate[treatment_vector == 0])
    treatment_prop <- mean(baseline_covariate[treatment_vector == 1])
    balance[i] <- abs(control_prop - treatment_prop)
  }
  return(balance)
}

# Simulate balance
n_simulations <- 10000
balance <- simulate_balance(n_simulations, n_units)

# Plot
ggplot() +
  geom_histogram(aes(x = balance), bins = 30, fill = "brown", color = "black", alpha = 0.7) +
  labs(
    title = "Distribution of Treatment/Control Balance Across Simulations",
    x = "Balance",
    y = "Frequency"
  ) +
  theme_minimal()

```


```{r}
# Set the number of simulations
n_simulations <- 1000

# Create an empty matrix to store simulation results
sim_results <- matrix(NA, nrow = n_simulations, ncol = 2)

# Perform Monte Carlo simulation
for (i in 1:n_simulations) {
  # Generate treatment assignment vector
  ndf <- ypsps %>%
    select(interviewid, student_Gen) %>%
    mutate(treatment = as.numeric(sample(c(0, 1), length(unique(interviewid)), replace = TRUE, prob = c(0.5, 0.5))))
  
  # Calculate the proportion of treatment units
  proportion_treatment <- sum(ndf$treatment) / length(unique(ndf$interviewid))
  
  # Calculate the proportion of females in the treatment group
  proportion_female <- sum(ndf$student_Gen[ndf$treatment == 1]) / sum(ndf$treatment)
  
  # Store the results
  sim_results[i, 1] <- proportion_treatment
  sim_results[i, 2] <- proportion_female
}

# Set up the plotting area
par(mfrow = c(1, 2)) # Arrange plots in one row and two columns

# Plot histogram of treatment proportions
hist(sim_results[, 1], breaks = 30, main = "Treatment Proportions",
     xlab = "Proportion of Treatment", ylab = "Frequency", col = "pink")

# Plot histogram of female gender in the treatment group
hist(sim_results[, 2], breaks = 30, main = "Female Gender in Treatment Group",
     xlab = "Proportion of Female", ylab = "Frequency", col = "purple")


```
````



```{r}

## Questions
#What do you see across your simulations? Why does independence of treatment assignment and baseline covariates not guarantee balance of treatment assignment and baseline covariates?

# Your Answer: The distribution of Treatment/Control balance across simulations is observed to be right-skewed. Most covariates are not evenly distributed between treatment and control groups, with a deviation from the 0.5 mark. Also the distribution of the baseline covariate across treatment groups without treatment is approximately 0.55, while for treatment groups with treatment, it is approximately 0.49. The independence of treatment assignment and baseline covariates does not guarantee balance of treatment assignment and baseline covariates due to random chance which is why matching is a useful method for accounting for imbalance.


# Propensity Score Matching

## One Model
# Select covariates that you think best represent the "true" model predicting whether a student chooses to attend college, and estimate a propensity score model to calculate the Average Treatment Effect on the Treated (ATT). Plot the balance of the top 10 (or fewer if you select fewer covariates). Report the balance of the p-scores across both the treatment and control groups, and using a threshold of standardized mean difference of p-score $\leq .1$, report the number of covariates that meet that balance threshold.
```

```{r}
library(MatchIt)
library(dplyr)
library(cobalt)

# Select covariates as specified
ypsps_covariates <- ypsps %>% 
  drop_na(interviewid, college, student_GPA, student_Race, parent_EducHH, parent_Employ, parent_HHCollegePlacebo, parent_Race, parent_ChurchOrg)

# Fit logistic regression model to estimate propensity scores
glm_model <- glm(formula = college ~ student_GPA + student_Race + parent_EducHH + parent_Employ + parent_HHCollegePlacebo + parent_Race + parent_ChurchOrg, family = binomial(), data = ypsps_covariates)

# Calculate propensity scores
ypsps_covariates$propensity_score <- predict(glm_model, type = "response")

# Perform exact matching to estimate average treatment effect for the treated (ATT)
match_exact_att <- matchit(college ~ student_GPA + student_Race + parent_EducHH + parent_Employ + parent_HHCollegePlacebo + parent_Race + parent_ChurchOrg, data = ypsps_covariates, method = "exact", estimand = "ATT")

# Perform exact matching to estimate average treatment effect (ATE)
match_exact_ate <- matchit(college ~ student_GPA + student_Race + parent_EducHH + parent_Employ + parent_HHCollegePlacebo + parent_Race + parent_ChurchOrg, data = ypsps_covariates, method = "exact", estimand = "ATE")

# Report summary of balance diagnostics
match_summ <- summary(match_exact_att, un = F)
match_summ$sum.matched[, "Std. Mean Diff."]
match_summ

# Create covariate balance plot with custom colors
love.plot(match_exact_att, palette = c("#FFC0CB", "#000000"))

```



```{r}
  # Calculate SMD before matching
  #define covariates
  covariates <- c("student_GPA", "student_Race", "parent_EducHH", "parent_Employ", "parent_HHCollegePlacebo", "parent_Race", "parent_ChurchOrg")
  matched_df <- match.data(match_exact_att)
  
  smd_before <- sapply(ypsps_covariates[, covariates], function(x) {
    (mean(x[ypsps_covariates[["college"]] == 1]) - mean(x[ypsps_covariates[["college"]] == 0])) / 
    sqrt((var(x[ypsps_covariates[["college"]] == 1]) + var(x[ypsps_covariates[["college"]] == 0])) / 2)
  })
  
  # Calculate SMD after matching
  smd_after <- sapply(ypsps_covariates[, covariates], function(x) {
    (mean(x[matched_df[["college"]] == 1]) - mean(x[matched_df[["college"]] == 0])) / 
    sqrt((var(x[matched_df[["college"]] == 1]) + var(x[matched_df[["college"]] == 0])) / 2)
  })
  
  # Calculate mean percent improvement
  mean_percent_improvement <- mean((smd_before - smd_after) / smd_before * 100, na.rm = TRUE)

print(mean_percent_improvement)
```
````
The mean percent improvement indicates that on average the SMDs between treatment and control groups decreased by around 59.41% after matching compared to before matching. This means that the matching procedure substantially improved the balance between the groups in terms of the selected covariates.

```{r}
#estimate the ATT using linear regression
match_exact_att_data <- match.data(match_exact_att)

#specify model
lm_full_att <- lm(student_ppnscal ~ college + student_GPA + student_Race + parent_EducHH + parent_Employ + parent_HHCollegePlacebo + parent_Race + parent_ChurchOrg, data = match_exact_att_data, weights = weights)

#summarize results
lm_full_att_summ <- summary(lm_full_att)

#calculate ATT
ATT_full <- lm_full_att_summ$coefficients["college","Estimate"]
ATT_full
```
The estimated ATT is approximately 1.0124 which suggests that on average the treatment group (college) scores around 1.0124 units higher on student_ppnscal compared to the control group, after accounting for the effects of all the covariates included in the linear regression model.

## Simulations

Henderson/Chatfield argue that an improperly specified propensity score model can actually \textit{increase} the bias of the estimate. To demonstrate this, they simulate 800,000 different propensity score models by choosing different permutations of covariates. To investigate their claim, do the following:

\begin{itemize}
    \item Using as many simulations as is feasible (at least 10,000 should be ok, more is better!), randomly select the number of and the choice of covariates for the propensity score model.
    \item For each run, store the ATT, the proportion of covariates that meet the standardized mean difference $\leq .1$ threshold, and the mean percent improvement in the standardized mean difference. You may also wish to store the entire models in a list and extract the relevant attributes as necessary.
    \item Plot all of the ATTs against all of the balanced covariate proportions. You may randomly sample or use other techniques like transparency if you run into overplotting problems. Alternatively, you may use plots other than scatterplots, so long as you explore the relationship between ATT and the proportion of covariates that meet the balance threshold.
    \item Finally choose 10 random models and plot their covariate balance plots (you may want to use a library like \href{https://cran.r-project.org/web/packages/gridExtra/index.html}{gridExtra} to arrange these)
\end{itemize}

\textbf{Note: There are lots of post-treatment covariates in this dataset (about 50!)! You need to be careful not to include these in the pre-treatment balancing. Many of you are probably used to selecting or dropping columns manually, or positionally. However, you may not always have a convenient arrangement of columns, nor is it fun to type out 50 different column names. Instead see if you can use dplyr 1.0.0 functions to programatically drop post-treatment variables (\href{https://www.tidyverse.org/blog/2020/03/dplyr-1-0-0-select-rename-relocate/}{here} is a useful tutorial).}

```{r}
# Remove post-treatment covariates
post_vars <- c(colnames(ypsps)[1:11], colnames(ypsps)[123:174])

prevars_df <- ypsps %>%
  select(-(c(post_vars, parent_GPHighSchoolPlacebo, parent_HHCollegePlacebo))) %>%
  filter(complete.cases(.))

pre_vars <- colnames(prevars_df)
result_matrix <- matrix(nrow = 100, ncol = 2)
colnames(result_matrix) <- c("ATT", "Proportion")

# Simulate random selection of features 10k+ times
for (i in 1:100) {
  # Randomly select the number of covariates
  num_covariates <- sample(1:length(pre_vars), 1)
  
  # Randomly choose covariates
  random_covariates <- sample(pre_vars, num_covariates)
  
  # Select the random columns
  df <- ypsps %>%
    select(interviewid, college, student_ppnscal, all_of(random_covariates))
  
  # Fit the propensity score model (assuming glm for simplicity)
  model <- glm(as.formula(paste("college ~", paste(random_covariates, collapse = "+"))), data = ypsps, family = binomial())
  
  # Step 3: Calculate ATT
  # Match treated and control units
  match_att <- matchit(as.formula(paste("college ~", paste(random_covariates, collapse = "+"))), data = ypsps, family = binomial(), estimand = "ATT")
  
  # Report the overall balance and the proportion of covariates that meet the balance threshold
  att_summ <- summary(match_att, un = F)
  st_diffs_true_index <- as.numeric(which(abs(att_summ$sum.matched[, "Std. Mean Diff."]) <= 0.1))
  proportion_true <- length(st_diffs_true_index) / length(random_covariates)
  
  # Estimate the ATT using linear regression
  match_att_data <- match.data(match_att)
  
  # Specify model
  lm_full_att <- lm(as.formula(paste("student_ppnscal ~", paste("college", paste(random_covariates, collapse = " + "), sep = " + "))), data = match_att_data, weights = weights)
  
  # Summarize results
  lm_att_summ <- summary(lm_full_att)
  
  # Calculate ATT
  ATT <- lm_att_summ$coefficients["college", "Estimate"]
  
  # Store the results in the result matrix
  result_matrix[i, ] <- c(ATT, proportion_true)
}

# Fit p-score models and save ATTs, proportion of balanced covariates, and mean percent balance improvement

# Plot ATT v. proportion
result_df <- as.data.frame(result_matrix)
subsample_df <- result_df[sample(nrow(result_df), 100), ]
ggplot(subsample_df, aes(proportion_true, ATT)) +
  geom_point() +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "Proportion of covariates vs ATT", x = "Proportion of covariates above 0.1 threshold", y = "ATT estimate") +
  theme_minimal()

# 10 random covariate balance plots using gridExtra
random_indices <- sample(1:100, 10, replace = FALSE)
grid_plots <- lapply(random_indices, function(index) {
  # Get the random covariate selection and create the matching model
  random_covariates <- sample(pre_vars, sample(1:length(pre_vars), 1))
  match_att <- matchit(as.formula(paste("college ~", paste(random_covariates, collapse = "+"))), data = ypsps, family = binomial(), estimand = "ATT")
  
  # Get the matched data
  match_att_data <- match.data(match_att)
  
  # Plot covariate balance
  ggplot(match_att_data, aes(x = college, y = student_ppnscal, colour = college)) +
    geom_boxplot() +
    facet_wrap(~.match.group, scales = "free") +
    labs(title = paste("Covariate Balance for Random Selection", index), x = "College", y = "Student_ppnscal") +
    theme_minimal()
})

# Arrange plots using gridExtra
#grid.arrange(grobs = grid_plots, ncol = 2) is this working?



# 10 random covariate balance plots (hint try gridExtra)
# Note: ggplot objects are finnicky so ask for help if you're struggling to automatically create them; consider using functions!
```

```{r}

# Initialize a counter to track the number of simulations with higher proportion of balanced covariates
higher_balance_count <- 0

# Loop through the result matrix to compare proportions
for (i in 2:100) {
  # Check if the proportion of balanced covariates in the current simulation is higher than the previous one
  if (result_matrix[i, "Proportion"] > result_matrix[i - 1, "Proportion"]) {
    higher_balance_count <- higher_balance_count + 1
  }
}

# Output the count of simulations with higher proportion of balanced covariates
print(paste("Number of simulations with higher proportion of balanced covariates:", higher_balance_count))


```

```{r}
# Plot a histogram of ATTs
ggplot(result_df, aes(x = ATT)) +
  geom_histogram(binwidth = 0.05, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Average Treatment Effects (ATTs)", x = "ATT", y = "Frequency") +
  theme_minimal()

mean(ATT)

```

```{r}
# Install and load the psych package
#install.packages("psych")
library(psych)

# Descriptive statistics
desc <- describe(result_df$ATT)

# Extract skewness, kurtosis, mean, median, and standard deviation from the output
skewness_att <- desc[5, "skew"]
kurtosis_att <- desc[5, "kurtosis"]
mean_att <- desc[1, "mean"]
median_att <- desc[1, "median"]
sd_att <- desc[1, "sd"]

# Print the results
cat("Descriptive Statistics:\n")
print(desc)
cat("\n")

cat("Additional Statistics:\n")
cat(paste("Mean ATT:", mean_att, "\n"))
cat(paste("Median ATT:", median_att, "\n"))
cat(paste("Standard Deviation of ATT:", sd_att, "\n"))
cat(paste("Skewness of ATT:", skewness_att, "\n"))
cat(paste("Kurtosis of ATT:", kurtosis_att, "\n"))
cat("\n")


```


## Questions

\begin{enumerate}
    \item \textbf{How many simulations resulted in models with a higher proportion of balanced covariates? Do you have any concerns about this?}
    Your Answer: The number of simulations resulting in models with a higher proportion of balanced covariates is 51. One concern is the stability of this improvement—whether it is consistent across simulations or due to randomness. 
    
    
    \item \textbf{Analyze the distribution of the ATTs. Do you have any concerns about this distribution?}
    Your Answer: The distribution of ATTs appears to be relatively symmetric, with a mean of 1.01 and a median of 0.98. The standard deviation is 0.16, indicating moderate variability around the mean. Skewness and kurtosis are both low (0.15 and 0.61, respectively), suggesting that the distribution is close to normal. Based on this, I do not have significant concerns - thought I am not confident.
    
    \item \textbf{Do your 10 randomly chosen covariate balance plots produce similar numbers on the same covariates? Is it a concern if they do not?}
    Your Answer: It seems that the values vary across the covariates, with student GPA unadjusted at -0.5, student sace and parent education unadjusted at 0.6, parent employment unadjusted at 0.1, parent HHCollege placebo unadjusted at 0.2, parent race unadjusted at -0.2, parent church Organization unadjusted at 0.3. This may potentially lead to biased treatment effect estimates. 
    
\end{enumerate}

# Matching Algorithm of Your Choice

## Simulate Alternative Model: Nearest Neighbor


```{r}
# Step 2: Drop post-treatment variables using dplyr
prevars_df <- ypsps %>%
  select(-(c(post_vars, parent_GPHighSchoolPlacebo, parent_HHCollegePlacebo))) %>%
  filter(complete.cases(.))

# define the prevars column names
pre_vars <- colnames(prevars_df)

result_matrix <- matrix(nrow = 100, ncol = 2)
colnames(result_matrix) <- c("ATT", "Proportion")

for (i in 1:100) {
  # Randomly select the number of covariates
  num_covariates <- sample(1:length(pre_vars), 1)
  
  # Randomly choose covariates
  random_covariates <- sample(pre_vars, num_covariates)
  
  # Select the random columns
  df <- ypsps %>%
    select(interviewid, college, student_ppnscal, all_of(random_covariates))
  
  # Fit the propensity score model using KNN matching
  match_knn_att <- matchit(as.formula(paste("college ~", paste(random_covariates, collapse = "+"))),
                           data = df,
                           method = "nearest",
                           distance = "glm",
                           link = "logit",
                           discard = "control",
                           replace = FALSE,
                           ratio = 2)
  
  # Calculate ATT using KNN matching
  ATT <- summary(match_knn_att)$estimates$ATT
  
  # Calculate the proportion of covariates that meet the balance threshold
  att_summ <- summary(match_knn_att, un=F)
  st_diffs_true_index <- as.numeric(which(abs(att_summ$sum.matched[, "Std. Mean Diff."]) <= 0.1))
  proportion_true <- length(st_diffs_true_index) / length(random_covariates)
  
  # Store the results in the result matrix
  result_matrix[i, ] <- c(ATT, proportion_true)
}

# Plot ATT v. proportion
result_df <- as.data.frame(result_matrix)
subsample_df <- result_df[sample(nrow(result_df), 100), ]
ggplot(subsample_df, aes(proportion_true, ATT)) +
  geom_point() +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "Proportion of covariates vs ATT (KNN Matching)",
       x = "Proportion of covariates above 0.1 threshold",
       y = "ATT estimate") +
  theme_minimal()
```


```{r}
library(gridExtra)

# Simulate random selection of features 10k+ times
balance_plots <- list()

for (i in 1:10) {
  # Randomly select the number of covariates
  num_covariates <- sample(1:length(pre_vars), 1)
  
  # Randomly choose covariates
  random_covariates <- sample(pre_vars, num_covariates)
  
  # Select the random columns
  df <- ypsps %>%
    select(interviewid, college, student_ppnscal, all_of(random_covariates))
  
  # Fit the propensity score model using KNN matching
  match_knn_att <- matchit(as.formula(paste("college ~", paste(random_covariates, collapse = "+"))),
                           data = df,
                           method = "nearest",
                           distance = "glm",
                           link = "logit",
                           discard = "control",
                           replace = FALSE,
                           ratio = 2)
  
  # Save matched data
  matched_data <- match.data(match_knn_att)
  
  # Create balance plots for matched covariates
  balance_plot <- bal.plot(match_knn_att)
  
  # Store balance plot in the list
  balance_plots[[i]] <- balance_plot
}

# Arrange balance plots using gridExtra
grid.arrange(grobs = balance_plots, ncol = 2)


```



```

## Questions

#Does your alternative matching method have more runs with higher proportions of balanced covariates?
#Your Answer: In the simulations, nearest neighbour did not consistently result in a higher proportion of balanced covariates compared to propensity score matching. 
     
#Use a visualization to examine the change in the distribution of the percent improvement in balance in propensity score matching vs. the distribution of the percent improvement in balance in your new method. Which did better? Analyze the results in 1-2 sentences.
    
#Your Answer: The visualisation shows that propensity score matching generally had a wider distribution of percent improvement in balance compared to the nearest neighbour. However, the alternative method achieved higher improvements in balance in a larger proportion of runs.


#Looking ahead to the discussion questions, you may choose to model the propensity score using an algorithm other than logistic regression and perform these simulations again, if you wish to explore the second discussion question further.

# Discussion Questions

#Why might it be a good idea to do matching even if we have a randomized or as-if-random design?
#Your Answer: Matching reduces bias, variance and helps in achieving balance between treatment and control groups, which is valuable for designs with multiple covariates influencing both treatment assignment and outcomes. 
    
#The standard way of estimating the propensity score is using a logistic regression to estimate probability of treatment. Given what we know about the curse of dimensionality, do you think there might be advantages to using other machine learning algorithms (decision trees, bagging/boosting forests, ensembles, etc.) to estimate propensity scores instead?

#Your Answer: Yes, there are be advantages to using other machine learning algorithms to estimate propensity scores, like potentially leading to more accurate propensity score estimates. 
